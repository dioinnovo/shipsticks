# Hybrid GraphRAG Architecture - Critical Changes

**Date**: January 13, 2025
**Status**: Architecture Redesigned Based on Research

---

## Critical Issues in Original Approach

### ‚ùå Issue 1: Rigid Predefined Schema
**Original**: Hardcoded 7 entity types, 8 relationship types
**Problem**: Can't discover healthcare patterns we don't know about
**Solution**: **LLM-driven schema discovery** + hybrid extraction

### ‚ùå Issue 2: Batch ETL (Not True Incremental)
**Original**: Daily Spark batch jobs with full MERGE operations
**Problem**: Could trigger graph recomputation, not real-time
**Solution**: **Spark Structured Streaming** + temporal properties (Graphiti pattern)

### ‚ùå Issue 3: Ignoring SQL Metadata
**Original**: Manually mapping tables to entities
**Problem**: Foreign keys already encode relationships!
**Solution**: **Automated SQL schema analysis** using LLM

---

## New Hybrid Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   PHASE 1: SCHEMA DISCOVERY                      ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Synapse SQL Metadata                                           ‚îÇ
‚îÇ  - Tables, columns                                              ‚îÇ
‚îÇ  - Foreign keys (relationships!)                                ‚îÇ
‚îÇ  - Indexes, row counts                                          ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  LLM Schema Discovery Agent                                     ‚îÇ
‚îÇ  - Analyzes structure                                           ‚îÇ
‚îÇ  - Discovers entities                                           ‚îÇ
‚îÇ  - Maps FK ‚Üí relationships                                      ‚îÇ
‚îÇ  - Infers implicit patterns                                     ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Proposed Healthcare Ontology                                   ‚îÇ
‚îÇ  - Core entities (Patient, Diagnosis, etc.)                     ‚îÇ
‚îÇ  - Discovered entities (CareEpisode, ReferralNetwork, etc.)     ‚îÇ
‚îÇ  - Explicit relationships (from FKs)                            ‚îÇ
‚îÇ  - Inferred relationships (patterns)                            ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Human Review & Approval                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PHASE 2: HYBRID EXTRACTION (Initial Load)           ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  LangChain LLMGraphTransformer                                  ‚îÇ
‚îÇ  ‚îú‚îÄ REQUIRED entities (approved core)                           ‚îÇ
‚îÇ  ‚îú‚îÄ OPEN-ENDED discovery (allowed_nodes=[])                     ‚îÇ
‚îÇ  ‚îî‚îÄ Autonomous property extraction                              ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Synapse SQL Tables                                             ‚îÇ
‚îÇ  - Structured data                                              ‚îÇ
‚îÇ  - Text columns (policies, narratives)                          ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Neo4j Knowledge Graph                                          ‚îÇ
‚îÇ  - All nodes have temporal properties                           ‚îÇ
‚îÇ  - All relationships have timestamps                            ‚îÇ
‚îÇ  - Ready for incremental updates                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         PHASE 3: REAL-TIME INCREMENTAL UPDATES (Ongoing)         ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Synapse SQL Changes                                            ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Change Data Capture (CDC)                                      ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Azure Event Hubs                                               ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Spark Structured Streaming                                     ‚îÇ
‚îÇ  - Reads stream                                                 ‚îÇ
‚îÇ  - Timestamp-based processing                                   ‚îÇ
‚îÇ  - No full table scans                                          ‚îÇ
‚îÇ           ‚Üì                                                      ‚îÇ
‚îÇ  Neo4j Incremental MERGE                                        ‚îÇ
‚îÇ  - Match by ID                                                  ‚îÇ
‚îÇ  - Update lastModified                                          ‚îÇ
‚îÇ  - Temporal edge invalidation                                   ‚îÇ
‚îÇ  - NO full graph recomputation                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Key Improvements

### 1. LLM Schema Discovery Agent
**File**: `lib/graphrag/schema-discovery-agent.ts`

**What It Does**:
- Analyzes Synapse INFORMATION_SCHEMA
- Reads foreign keys, indexes, column types
- Uses GPT-4o to discover:
  - **Core entities** (Patient, Diagnosis, Medication, Provider, Facility, Procedure)
  - **Discovered entities** (CareEpisode, ReferralNetwork, QualityMeasure, etc.)
  - **Explicit relationships** (from foreign keys)
  - **Inferred relationships** (from patterns, junction tables, timestamps)

**Example Output**:
```json
{
  "coreEntities": [
    {
      "name": "Patient",
      "sourceTable": "patients",
      "confidence": "high",
      "keyProperties": ["id", "mrn", "insurancePlanId"]
    }
  ],
  "discoveredEntities": [
    {
      "name": "CareEpisode",
      "sourceTable": "encounters",
      "description": "Represents a care journey from admission to discharge",
      "confidence": "medium",
      "reasoning": "Encounters table has episode_id suggesting care continuity tracking"
    }
  ],
  "explicitRelationships": [
    {
      "name": "PRESCRIBED",
      "sourceEntity": "Patient",
      "targetEntity": "Medication",
      "sqlBasis": "FK: prescriptions.patient_id ‚Üí patients.id",
      "healthcareSemantics": "Patient is prescribed this medication",
      "confidence": "high"
    }
  ],
  "inferredRelationships": [
    {
      "name": "FOLLOWS_CARE_PATH",
      "sourceEntity": "Patient",
      "targetEntity": "CareEpisode",
      "sqlBasis": "Temporal sequence of encounters with same episode_id",
      "healthcareSemantics": "Patient follows a care pathway over time",
      "confidence": "medium"
    }
  ]
}
```

---

### 2. Hybrid Entity Extraction Strategy

**Instead of**: Hardcoded schema
**Now**: Flexible schema with minimum requirements + LLM discovery

**Using LangChain LLMGraphTransformer**:

```python
from langchain_experimental.graph_transformers import LLMGraphTransformer

# Minimum required (approved by human)
REQUIRED_NODES = ["Patient", "Diagnosis", "Medication", "Provider", "Facility", "Procedure"]
REQUIRED_RELATIONSHIPS = ["HAS_DIAGNOSIS", "PRESCRIBED", "VISITED", "PERFORMED"]

# LLM can discover additional entities/relationships
transformer = LLMGraphTransformer(
    llm=llm,
    allowed_nodes=REQUIRED_NODES + [],  # Empty list = open-ended
    allowed_relationships=REQUIRED_RELATIONSHIPS + [],  # Open-ended
    node_properties=True,  # LLM extracts properties
    relationship_properties=True
)
```

---

### 3. True Incremental Updates (No Recomputation)

**Key Pattern: Temporal Properties on Everything**

```cypher
// Every node has timestamps
CREATE (p:Patient {
  id: 'PAT-001',
  mrn: 'MRN-12345',
  firstName: 'John',
  lastName: 'Smith',

  // TEMPORAL PROPERTIES (required for incremental updates)
  createdAt: datetime('2024-01-15T10:00:00Z'),
  lastModified: datetime('2025-01-13T14:30:00Z'),
  validFrom: datetime('2024-01-15T10:00:00Z'),
  validTo: NULL  // NULL = currently valid
})

// Every relationship has timestamps
CREATE (p)-[:PRESCRIBED {
  prescribedDate: date('2024-06-01'),
  dosage: '500mg',
  adherenceScore: 0.85,

  // TEMPORAL PROPERTIES
  createdAt: datetime('2024-06-01T09:00:00Z'),
  lastModified: datetime('2025-01-10T11:00:00Z'),
  validFrom: datetime('2024-06-01T09:00:00Z'),
  validTo: NULL  // Currently valid
}]->(m:Medication)
```

**Spark Structured Streaming**:

```python
# Read only NEW/CHANGED data (not full table!)
spark.readStream \
    .format("org.neo4j.spark.DataSource") \
    .option("streaming.property.name", "lastModified")  # Key option!
    .option("streaming.from", "NOW")  # Only new changes
    .load()

# Write with incremental MERGE
spark.writeStream \
    .format("org.neo4j.spark.DataSource") \
    .option("checkpointLocation", "/checkpoints/patients")
    .option("node.keys", "id")  # Match by ID (not full scan!)
    .start()
```

**Temporal Edge Invalidation** (Graphiti pattern):

```cypher
// When a prescription changes, don't delete old relationship
// Instead, invalidate it temporally

// Old relationship
MATCH (p:Patient {id: 'PAT-001'})-[r:PRESCRIBED]->(m:Medication {id: 'MED-001'})
WHERE r.validTo IS NULL  // Currently valid
SET r.validTo = datetime()  // Mark as no longer valid

// Create new relationship with updated information
CREATE (p)-[:PRESCRIBED {
  prescribedDate: date('2025-01-13'),
  dosage: '1000mg',  // Changed dosage
  adherenceScore: 0.90,
  createdAt: datetime(),
  lastModified: datetime(),
  validFrom: datetime(),
  validTo: NULL  // New valid relationship
}]->(m)
```

---

## Implementation Files Created

### 1. Schema Discovery Agent
- **File**: `lib/graphrag/schema-discovery-agent.ts` (‚úÖ Created)
- **Purpose**: LLM analyzes Synapse schema
- **Output**: Discovered entities/relationships + Neo4j DDL

### 2. Synapse Schema Reader
- **File**: `lib/graphrag/synapse-schema-reader.ts` (‚úÖ Created)
- **Purpose**: Reads INFORMATION_SCHEMA from Synapse
- **Extracts**: Tables, columns, FKs, indexes, row counts

### 3. Discovery Script
- **File**: `scripts/discover-schema.ts` (‚úÖ Created)
- **Usage**: `npx tsx scripts/discover-schema.ts`
- **Outputs**:
  - `schema-discovery-report.md` (human review)
  - `neo4j-discovered-schema.cypher` (DDL)
  - `schema-discovery.json` (programmatic use)

---

## Next Steps (In Order)

### ‚úÖ Completed:
1. Schema discovery agent implementation
2. Synapse schema reader
3. Discovery script

### üîÑ In Progress:
4. **LangChain LLMGraphTransformer wrapper** with hybrid extraction

### üìã Pending:
5. Spark Structured Streaming CDC pipeline
6. Temporal MERGE strategy implementation
7. Event Hubs CDC configuration
8. Complete documentation update

---

## Decision Points (Need User Input)

### Question 1: Graphiti Integration?
**Option A**: Keep Neo4j + implement Graphiti temporal patterns ourselves (‚úÖ Recommended)
- **Pros**: No event loop issues, full control, simpler architecture
- **Cons**: We implement temporal logic ourselves

**Option B**: Deploy Graphiti as separate microservice
- **Pros**: Built-in temporal graph management
- **Cons**: Event loop conflicts, additional infrastructure, microservice complexity

**Recommendation**: **Option A** - We've already designed the temporal properties approach.

---

### Question 2: LLM Discovery Scope?
**Option A**: Fully open (allowed_nodes=[], allowed_relationships=[])
- **Pros**: Maximum discovery of unknown patterns
- **Cons**: May find spurious relationships, higher LLM costs

**Option B**: Hybrid (7 core + open for rest) (‚úÖ Recommended)
- **Pros**: Guaranteed core entities + discovery of additional patterns
- **Cons**: Slightly more constrained

**Recommendation**: **Option B** - Best balance of guidance + discovery.

---

### Question 3: Real-Time Latency?
**Option A**: Near real-time (1-5 minute lag via Spark Streaming) (‚úÖ Recommended)
- **Pros**: Proven architecture, handles scale, reasonable latency
- **Cons**: Not sub-second

**Option B**: True real-time (sub-second via Kafka + direct Neo4j)
- **Pros**: Minimal latency
- **Cons**: More complex, higher costs, may not be necessary

**Recommendation**: **Option A** - 1-5 minute latency is acceptable for healthcare analytics.

---

## Architecture Comparison

| Aspect | Original (Rigid) | New (Hybrid) |
|--------|------------------|--------------|
| **Entity Discovery** | Hardcoded 7 types | LLM discovers + core minimum |
| **Relationship Discovery** | Hardcoded 8 types | LLM discovers from FKs + patterns |
| **ETL Strategy** | Batch daily | Streaming incremental |
| **Graph Updates** | Full MERGE (may recompute) | Timestamp-based incremental |
| **SQL Metadata Usage** | Ignored | Analyzed by LLM |
| **Temporal Support** | Basic timestamps | Bi-temporal (Graphiti pattern) |
| **Gap Discovery** | Predefined queries | Emergent from discovered relationships |
| **Flexibility** | Low | High |
| **LLM Cost** | Low (no discovery) | Medium (discovery + extraction) |

---

## Key Research Findings

### LightRAG
- ‚úÖ Automatic entity/relationship extraction from text
- ‚úÖ Hybrid retrieval (vector + BM25 + graph traversal)
- ‚ùå Designed for **unstructured documents**, not SQL tables
- ‚ùå Hallucinates when given structured data

### Graphiti
- ‚úÖ True incremental updates without recomputation
- ‚úÖ Bi-temporal model (validFrom, validTo)
- ‚úÖ Temporal edge invalidation
- ‚ùå Event loop conflicts (requires microservice)
- ‚ùå Python-only (we're using TypeScript)

### LangChain LLMGraphTransformer
- ‚úÖ Schema-guided extraction
- ‚úÖ Supports open-ended discovery
- ‚úÖ Works with structured + unstructured data
- ‚úÖ TypeScript support
- ‚úÖ Flexible allowed_nodes/allowed_relationships

### Neo4j Spark Connector
- ‚úÖ Structured Streaming support
- ‚úÖ Timestamp-based incremental reads
- ‚úÖ Checkpoint-based fault tolerance
- ‚úÖ MERGE by key (no full scans)

---

## Success Criteria

### Phase 1: Schema Discovery
- ‚úÖ LLM discovers ‚â•5 non-obvious entities
- ‚úÖ Foreign keys mapped to relationships (100% coverage)
- ‚úÖ Inferred relationships identified
- ‚úÖ Human review report generated

### Phase 2: Hybrid Extraction
- ‚úÖ Core entities extracted (Patient, Diagnosis, Medication, Provider, Facility, Procedure)
- ‚úÖ Discovered entities extracted
- ‚úÖ LLM finds ‚â•3 additional relationship types not in original schema
- ‚úÖ All nodes have temporal properties

### Phase 3: Incremental Updates
- ‚úÖ New Synapse record ‚Üí Neo4j in <5 minutes
- ‚úÖ Updated record ‚Üí Neo4j relationship invalidated + new created
- ‚úÖ No full graph recomputation
- ‚úÖ Checkpoint-based fault tolerance works

---

## Next Immediate Action

**Run schema discovery**:

```bash
# Set environment variables
export SYNAPSE_SERVER="arthur-health-synapse.sql.azuresynapse.net"
export SYNAPSE_DATABASE="healthcare_fhir"
export SYNAPSE_USER="sqladmin"
export SYNAPSE_PASSWORD="your-password"
export AZURE_OPENAI_KEY="your-key"

# Run discovery
npx tsx scripts/discover-schema.ts
```

**Expected Output**:
- Console log of discovered entities/relationships
- `schema-discovery/schema-discovery-report-TIMESTAMP.md`
- `schema-discovery/neo4j-discovered-schema-TIMESTAMP.cypher`
- `schema-discovery/schema-discovery-TIMESTAMP.json`

**After Discovery**:
1. Review markdown report
2. Validate with healthcare domain experts
3. Approve or modify discovered schema
4. Proceed to implement hybrid extraction

---

**Ready to revolutionize healthcare analytics! üöÄ**
